{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final_cnn_ass3.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqAgjbXG5Dph"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from subprocess import check_output\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "from numpy import random\n",
        "import keras\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ReduceLROnPlateau, Callback\n",
        "from keras import regularizers\n",
        "from keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "from keras.optimizers import SGD\n",
        "from sklearn.utils import shuffle\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "LzaDvdP68MJS",
        "outputId": "0a560aab-0223-4de3-d1a8-5e1a1d8f52d2"
      },
      "source": [
        "data_train = pd.read_csv('/content/sample_data/mnist_test.csv')\n",
        "data_test = pd.read_csv('/content/sample_data/mnist_train_small.csv')\n",
        "\n",
        "print(\"data_train\" , data_train.shape)\n",
        "print(\"data_test\" , data_test.shape)\n",
        "\n",
        "# (data_x_train, data_y_train), (X_test,  y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# i_image = 2 \n",
        "# print(data_y_train[i_image]) \n",
        "# plt.imshow(data_x_train[i_image], cmap='Greys')\n",
        "\n",
        "img_rows, img_cols = 28, 28\n",
        "input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "X = np.array(data_train.iloc[:, 1:])\n",
        "y = to_categorical(np.array(data_train.iloc[:, 0]))\n",
        "\n",
        "#Here we split validation data to optimiza classifier during training\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=13)\n",
        "\n",
        "#Test data\n",
        "X_test = np.array(data_test.iloc[:, 1:])\n",
        "y_test = to_categorical(np.array(data_test.iloc[:, 0]))\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "X_train, y_train = shuffle(X_train, y_train)\n",
        "X_test, y_test = shuffle(X_test, y_test)\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
        "X_val = X_val.reshape(X_val.shape[0], img_rows, img_cols, 1)\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_val = X_val.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "X_val /= 255\n",
        "\n",
        "print(X_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data_train (9999, 785)\n",
            "data_test (19999, 785)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-73a1bbdf0c70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m#Here we split validation data to optimiza classifier during training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'to_categorical' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inbIzRuserLe"
      },
      "source": [
        "plt.figure(figsize=(5,5))\n",
        "plt.xticks(size=10)\n",
        "sns.countplot(y, linewidth = 2, edgecolor = sns.color_palette(\"Set2\"))\n",
        "plt.title(\" Label distribution of training dataset\", fontdict={\"color\": \"black\", \"fontsize\": 15})\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgpEQFPu8OH1",
        "outputId": "e76db3d8-88a3-4f0f-bd42-29e924b52b68"
      },
      "source": [
        "print(\"X_train:{}\\ny_train:{}\\n\\nX_val:{}\\ny_val:{}\\n\\nX_test:{}\\ny_test:{}\".format\n",
        "      (X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train:(48000, 28, 28, 1)\n",
            "y_train:(48000, 10)\n",
            "\n",
            "X_val:(12000, 28, 28, 1)\n",
            "y_val:(12000, 10)\n",
            "\n",
            "X_test:(10000, 28, 28, 1)\n",
            "y_test:(10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUKtGizI8Qjz"
      },
      "source": [
        "#m_1\n",
        "batch_size = 32\n",
        "num_classes = 10\n",
        "epochs = 10\n",
        "#input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 kernel_initializer='he_normal',\n",
        "                 input_shape=input_shape))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2),strides=2))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2),strides=2))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "opt = keras.optimizers.Adamax(learning_rate=0.001)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwc3cYL98SqP",
        "outputId": "1b8d5d6b-f808-4def-effc-e254e8603293"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 3, 3, 128)         73856     \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1152)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               147584    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 241,546\n",
            "Trainable params: 241,546\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yJfgKpc8St8",
        "outputId": "6d205e38-5f3e-406c-e23d-b746e0c0d963"
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(X_val, y_val))\n",
        "score = model.evaluate(X_test, y_test, verbose=0 , batch_size=128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 57s 37ms/step - loss: 0.6747 - accuracy: 0.7787 - val_loss: 0.0881 - val_accuracy: 0.9733\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 56s 37ms/step - loss: 0.1347 - accuracy: 0.9576 - val_loss: 0.0600 - val_accuracy: 0.9810\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 56s 37ms/step - loss: 0.0893 - accuracy: 0.9726 - val_loss: 0.0490 - val_accuracy: 0.9844\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 56s 38ms/step - loss: 0.0746 - accuracy: 0.9770 - val_loss: 0.0428 - val_accuracy: 0.9872\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 57s 38ms/step - loss: 0.0591 - accuracy: 0.9820 - val_loss: 0.0395 - val_accuracy: 0.9877\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 55s 37ms/step - loss: 0.0577 - accuracy: 0.9823 - val_loss: 0.0337 - val_accuracy: 0.9898\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 56s 37ms/step - loss: 0.0465 - accuracy: 0.9857 - val_loss: 0.0343 - val_accuracy: 0.9900\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 56s 37ms/step - loss: 0.0413 - accuracy: 0.9877 - val_loss: 0.0317 - val_accuracy: 0.9912\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 55s 37ms/step - loss: 0.0402 - accuracy: 0.9875 - val_loss: 0.0309 - val_accuracy: 0.9904\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 56s 37ms/step - loss: 0.0339 - accuracy: 0.9893 - val_loss: 0.0282 - val_accuracy: 0.9920\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jE5ZUuN8SxP",
        "outputId": "d8217267-7621-4049-c0ee-ba5b99512614"
      },
      "source": [
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.022011002525687218\n",
            "Test accuracy: 0.9921000003814697\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bos7p5IE8S1e",
        "outputId": "9cd2f63f-7b0d-4664-a6cd-01ec3d571e5a"
      },
      "source": [
        "#get the predictions for the test data\n",
        "predicted_classes = model.predict_classes(X_test)\n",
        "\n",
        "#get the indices to be plotted\n",
        "y_true = data_test.iloc[:, 0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxcht5Ed8eaQ",
        "outputId": "4666986d-0584-4edc-f133-fe27d8b21af6"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "target_names = [\"Class {}\".format(i) for i in range(num_classes)]\n",
        "print(classification_report(y_true, predicted_classes, target_names=target_names))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       0.09      0.09      0.09       980\n",
            "     Class 1       0.13      0.13      0.13      1135\n",
            "     Class 2       0.11      0.11      0.11      1032\n",
            "     Class 3       0.10      0.10      0.10      1010\n",
            "     Class 4       0.11      0.11      0.11       982\n",
            "     Class 5       0.09      0.09      0.09       892\n",
            "     Class 6       0.09      0.09      0.09       958\n",
            "     Class 7       0.10      0.10      0.10      1028\n",
            "     Class 8       0.10      0.10      0.10       974\n",
            "     Class 9       0.11      0.11      0.11      1009\n",
            "\n",
            "    accuracy                           0.10     10000\n",
            "   macro avg       0.10      0.10      0.10     10000\n",
            "weighted avg       0.10      0.10      0.10     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyIf2Fk38eee"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}